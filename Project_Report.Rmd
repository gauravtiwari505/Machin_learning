---
title: "PML_Project_Report"
author: "Gaurav Tiwari"
date: "11/12/2016"
output: html_document
---
# Prediction Assignment Writeup - Practical Machine Learning
## Introduction
One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.
In this project, we are given data from accelerometers on the belt, forearm, arm, and dumbell of 6 research study participants. 

Our training data consists of accelerometer data and a label identifying the quality of the activity the participant was doing. 
Our testing data consists of accelerometer data without the identifying label. Our goal is to predict the labels for the test set observations.

We will now go through the process below of creating a model, estimating the out of sample error and finally making the predictions for the test set observations.

At each step, I will try to describe the code, so that it induces more clarity and better readability.


## Data Preparation
First, we load the caret package, and read in the training and testing data csv files:
```{r,message=FALSE,warning=FALSE}
library(caret)
training <- read.csv("Data/pml-training.csv")
testing <- read.csv("Data/pml-testing.csv")
```

Next, we will randomly split the full training data into a smaller training (training1) and a validation subset (training2) so that we are able to estimate the out of sample errors.


```{r}
#Setting the seed for reproducability
set.seed(123)
inTrain <- createDataPartition(y=training$classe, p=0.7, list=F)
training1 <- training[inTrain, ]
training2 <- training[-inTrain, ]
```

The next step is to reduce the number of features by removing variables with 
1. Nearly zero variance.
2. Variables that are almost always NA.
3. Variables that donâ€™t make intuitive sense for prediction.

The process is to do the analysis on training1 dataset and remove it from both training1 and training2 dataset based on training1 analysis.

In addition, we are going to trim the dataset so as to remove the variables that we dont need for prediction based on intuitive sense. So the first 5 columns are removed from both the training1 and training2 dataset.

```{r}
# Nearly zero variance
near_zero <- nearZeroVar(training1)
training1 <- training1[, -near_zero]
training2 <- training2[, -near_zero]

# remove variables that are almost always NA
mostlyNA <- sapply(training1, function(x) mean(is.na(x))) > 0.95
training1 <- training1[, mostlyNA==F]
training2 <- training2[, mostlyNA==F]

# remove variables that don't make intuitive sense for prediction (X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp), which happen to be the first five variables
training1 <- training1[, -(1:5)]
training2 <- training2[, -(1:5)]
```

# Building the Model
Based on past experience with dataset of these type, I decided to start with a Random Forest Model. The goal was to see if it provides an acceptable performance. The process is to first fit the model on training1 and then follow a 3-fold cross validation to optimize the model using the "train" function.

```{r}
# instruct train to use 3-fold CV to select optimal tuning parameters
fitControl <- trainControl(method="cv", number=3, verboseIter=F)

# fit model on training1
fit <- train(classe ~ ., data=training1, method="rf", trControl=fitControl)
```

```{r}
# print final model to see tuning parameters it chose
fit$finalModel
```

As we can see, that the model decided to use 27 variables and 500 trees at each split.

# Model Evaluation & Selection

Based on our previous training, we can now use the fitted model to predict the "classe" variable in training2 dataset and check the results by using a confusion matrix so that we can get a comparison of the predicted vs the actual lables

```{r}
# use model to predict classe in validation set (training2)
prediction <- predict(fit, newdata=training2)

# show confusion matrix to get estimate of out-of-sample error
confusionMatrix(training2$classe, prediction)
```

As we can see, the accuracy for this model is 99.8%, giving an out of sample error of just 0.2%.

This is a fairly acceptable result in my opinion, so rather than trying additional algorithms, I will go ahead with the Random Forests to do the same prediction on the test set.

# Application of selected model on training

To have the most accurate predictions, I decided to train the model on the complete training dataset. This way we will have better prediction rather than what we would have achieved from just the training1 dataset. So we follow the same procedures as above for the entire training dataset.

```{r}
# remove variables with nearly zero variance for the entire training dataset
near_zero <- nearZeroVar(training)
training <- training[, -near_zero]
testing <- testing[, -near_zero]

# remove variables that are almost always NA
mostlyNA <- sapply(training, function(x) mean(is.na(x))) > 0.95
training <- training[, mostlyNA==F]
testing <- testing[, mostlyNA==F]

# remove variables that don't make intuitive sense for prediction (X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp), which happen to be the first five variables
training <- training[, -(1:5)]
testing <- testing[, -(1:5)]

# re-fit model using full training set (training)
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
fit <- train(classe ~ ., data=training, method="rf", trControl=fitControl)
```

# Predicting on testing dataset

Finally, we will use the fitted model to predict the classe varible on the testing dataset. We will create a function that writes the predictions for each cases to individual text files.

```{r}
# predict on test set
prediction <- predict(fit, newdata=testing)

# convert predictions to character vector
prediction <- as.character(prediction)

# create function to write predictions to files
write_results <- function(a) {
    n <- length(a)
    for(i in 1:n) {
        filename <- paste0("Prediction/problem_id_", i, ".txt")
        write.table(a[i], file=filename, quote=F, row.names=F, col.names=F)
    }
}

# create prediction files to submit
write_results(prediction)
```

